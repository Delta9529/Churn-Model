# -*- coding: utf-8 -*-
"""INSAID_CHURN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f9iHZwE9Kt0dA1awoRc1ozkLj4xM9uLS

Importing Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import drive
drive.mount('/content/drive')

"""Importing Data & Manipulation"""

data = pd.read_csv(r"/content/drive/MyDrive/Colab Notebooks/INSAID_churn/Churn.csv")

data.head()

data.columns

data.isnull().sum()

data = data.drop('customerID',axis = 1)

#Checking the number of value counts
for i in data.columns:
    x = data[i].value_counts()
    print("Column name is:",i,"and it value is:",x) #The data looks fine no class imbalance

data.dtypes

data['TotalCharges'] = pd.to_numeric(data['TotalCharges'],errors = 'ignore') #Converting TotalCharges from Object to float

data['TotalCharges'] = data['TotalCharges'].replace([" ","NaN"], 0).astype('float32') # Replacing some of the errors in the column because it showed error while model fitting

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
data[['gender','Partner','Dependents','PhoneService','MultipleLines','InternetService','OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies','Contract','PaperlessBilling','PaymentMethod','Churn']] = data[['gender','Partner','Dependents','PhoneService','MultipleLines','InternetService','OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies','Contract','PaperlessBilling','PaymentMethod','Churn']].apply(le.fit_transform)

data.head()

"""Data Visualisation"""

data.hist(figsize=(20,15))

sns.catplot(x="Churn", y="MonthlyCharges",kind ='box',data=data) #People whose monthly charges are higher tend to leave

sns.catplot(x="Churn", y="tenure",kind ='box',data=data) #People with less tenure are likely to leave

"""Model fitting"""

x = data.drop('Churn',axis = 1)
y = data.Churn
print(x.shape)
print(y.shape)

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.41,random_state=0)
print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)

"""DecisionTree Classifier"""

from sklearn.tree import DecisionTreeClassifier
classifier0 = DecisionTreeClassifier(criterion = 'entropy',random_state =0)
classifier0.fit(x_train,y_train)

y_pred = classifier0.predict(x_test)
print(y_pred)

from sklearn.metrics import accuracy_score
acc= accuracy_score(y_test,y_pred)
acc

"""K-NN Classifiers"""

from sklearn.neighbors import KNeighborsClassifier
classifier1 = KNeighborsClassifier(n_neighbors = 5,metric = 'minkowski',p=2)
classifier1.fit(x_train,y_train)

y_pred_kn = classifier1.predict(x_test)
print(y_pred_kn)

from sklearn.metrics import accuracy_score
acc= accuracy_score(y_test,y_pred_kn)
acc

"""Logistic Regression"""

from sklearn.linear_model import LogisticRegression
classifier2 = LogisticRegression(random_state=0)
classifier2.fit(x_train,y_train)

y_pred_lg = classifier2.predict(x_test)
print(y_pred_lg)

from sklearn.metrics import accuracy_score
acc= accuracy_score(y_test,y_pred_lg)
acc

"""RandomForest Classifier"""

from sklearn.ensemble import RandomForestClassifier
classifier3 = RandomForestClassifier(n_estimators = 10,criterion ='entropy',random_state = 0)
classifier3.fit(x_train,y_train)

y_pred_rf = classifier3.predict(x_test)
print(y_pred_rf)

from sklearn.metrics import accuracy_score
acc= accuracy_score(y_test,y_pred_rf)
acc

"""LOGISTIC REGRESSION is the best model to fit

People whose monthly charges are higher tend to leave

People with less tenure are likely to leave
"""